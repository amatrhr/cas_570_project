








# modeling tools
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import statsmodels.api as sm
from copy import deepcopy
from random import randint, choice
from statsmodels.tsa.api import  SimpleExpSmoothing
from statsmodels.formula.api import ols
from statsmodels.stats.api import anova_lm

# programming and optimization tools
# import ipdb
from collections import Counter
from dataclasses import dataclass, field
from functools import partial
from itertools import product
from scipy.optimize import minimize_scalar
from scipy.stats import linregress


# parameters for the notebook itself
%matplotlib inline





def minmax_scale(data:np.array)->np.array:
    # function to scale a variable between 1 and 0, where 1 corresponds to its max value
    data = np.nan_to_num(data,0)
    vs_min = data - np.min(data)
    mmrange = np.max(data) - np.min(data) if np.max(data) != np.min(data) else 1
    scaled = vs_min / mmrange
    return scaled


def dbl_SEWMA(data:pd.Series, alpha:float)->dict:
    # fits a simple exponential smoothing model with fixed alpha to a dataset
    # used by simulated school (districts) to predict enrollment
    ## Arguments
    # data: univariate time series
    # alpha: exponential smoothing parameter, between 0 and 1
    ## Returns
    # dictionary containing the sum of squared errors and statsmodels time series model
    #TODO: fix initialization to use as few years as possible--this can only be done with "known" initial trend and level
    mod1 = SimpleExpSmoothing(data, initialization_method="heuristic").fit(smoothing_level=alpha, optimized=False)
    return {'sse':mod1.sse, 'mod':mod1}



def flat_with_noise(start_value:float=10.0, n_years:int=5, chgrat:float=0.20, const_change:float=None)->np.array:
    # generates a set of simulated enrollments that vary due to having noise
    ## Arguments
    ##
    ## Returns
    # np array of e
    output = np.zeros(n_years) + start_value
    chgsize = chgrat*start_value if const_change is None else const_change
    dmin = int(-1*chgsize)
    dmax = int(chgsize)
    output += np.array([randint(dmin, dmax) for x in range(n_years)],dtype=np.float64)
    return(output)


def impulse(start_value:float=10., n_years:int=5, impyr:int=2, chgrat:float=.670, impsign:int=1):
    # function to produce an impulsive change
    chgsize = chgrat*start_value
    out = np.array([start_value for x in range(n_years)],dtype=np.float64)
    out[impyr:n_years] = impsign*chgsize +  out[impyr]
    return(out)


def cvx_change(start_value=10., n_years=5, chgsign=1, chgrat=.20):
    #function to produce convex change
    # i.e. change where the time series of population falls below the line connecting any two
    # points on the time series, i.e. alpha*exp(t) or alpha*exp(n_years - t)
    chgsize = chgrat*start_value

    alpha = np.exp(np.log(1+chgsign*chgrat)/n_years) - 1
    output = start_value * np.power(1. + alpha, np.linspace(1,n_years,n_years))

    return(output)


def test_cvx_c_rat(start_value=10., n_years=5, chgsign=1, chgrat=.20, start_schools=5):
    # Function to check a ratio control strategy under convex change
    # ratio should be maintained if change in Nschools is proportional to the
    # current number of schools (i.e. exponential growth in the same way

    history = cvx_change(start_value=start_value, n_years=n_years, chgsign=chgsign, chgrat=chgrat)
    school_growth = cvx_change(start_value=start_schools, n_years=n_years, chgsign=chgsign, chgrat=chgrat)
    ratio = history/school_growth
    testval = np.allclose(ratio, max(ratio)*np.ones(len(ratio)))
    return testval


test_cvx_c_rat(n_years=99)


def ccv_change(start_value=10.,n_years=5,alpha=0.75,chgsign=1, chgrat=.20):
    # function to simulate concave change in a population
    # i.e. change where the time series of population falls above the line connecting any two
    # points on the time series, which is the part of a sine between 0 and 0.5pi
    # 
    adjust = 0.5*np.pi if chgsign < 0 else 0
    out = np.linspace(0,0.5*np.pi, n_years+1) # 
    out += adjust
    maxi = (1+chgrat*chgsign)*start_value
    mini = min(start_value, maxi)
    maxi = max(start_value, maxi)
    output = (maxi-mini)*np.sin(out) + mini # use half 
    return(output[1:])


# with individual growth patterns defined, store all in one easy-access place
growthPats = {'flat':flat_with_noise,
              'impUp':impulse,
              'impDn':partial(impulse, impsign=-1),
              'cvxUp':cvx_change,
              'cvxDn':partial(cvx_change, chgsign=-1),
              'ccvUp':ccv_change,
              'ccvDn':partial(ccv_change, chgsign=-1)
              }


def simulate_history(start_value=50, total_years=50, period_length=5, debug=False, noisy=False, set_history:list=None)->np.array:
    # core function to generate a school (district's) population history,
    # split up into a certain number of periods, each characterized by a differebt growth pattern
    

    history = [[start_value for x in range(period_length)]]
            # need to add functionality to smooth the transitions

    if set_history is not None:
        assert type(set_history) == list
        # since we know it's a list, assert that the length of the list is correct
        assert len(set_history) == total_years//period_length

    for _, tp in enumerate(range(total_years//period_length)):
        locidx = randint(0,len(growthPats)-1) if set_history is None else set_history[_] # there are 7 locidxs

        lochg = history[_][period_length-1]
        locfun = list(growthPats.values())[locidx](start_value=lochg, n_years=period_length)
        local_h = np.squeeze(locfun)
        if noisy:
            # add uniformly distributed noise
            local_h += np.squeeze(list(growthPats.values())[0](start_value=0., n_years=period_length, const_change=300.)) 

        history.append(local_h)
        if debug:
            '''debug info that shows which growth pattern is used and prints
               the starting value and simulated values for each multiyear
            '''
            print(f"starting history {locidx}, a/k/a {repr(list(growthPats.values())[locidx])}")
            print(_)
            print(lochg)
            print(local_h)
            print("____")

    out = np.floor(np.hstack(history)[period_length:])
    #print(out)
    return out # out[period_length:](why are we skipping the first period??)



def predict_from_history(schooldata:pd.Series,alpha_set:list=[0.1,0.5,0.7],years:int=5, random:bool=True)->dict:
    # core function to use simple exponential smoothing

    school_SEWMA = lambda a: dbl_SEWMA(data=schooldata, alpha=a) # 
    fit_res = {}
    models = {}
    if random:
        j = choice(alpha_set)
        ssmwa = school_SEWMA(j)
        fit_res[j] = ssmwa['sse']
        models[j] = ssmwa['mod']
    else:
        for j in alpha_set:
            # don't overwrite if there're multiples
            if fit_res.get(j) is None:
                ssmwa = school_SEWMA(j)
                fit_res[j] = ssmwa['sse']
                models[j] = ssmwa['mod']

    fit_check = pd.Series(fit_res)
    result = fit_check.index[fit_check.argmin()]
    return {"alpha_result":result, "prediction":models[result].forecast(years),"history":models[result].fittedvalues}


def get_run_lengths(timeseries:np.array=np.array([1.,1.,1.,22,22.,22.,3.,4.,3.]))->list:
    # give the number of time steps between school openings/closings
    loct = np.diff(timeseries) # a run is the same as no differences betweeen an item and its predecessor in the array
    loct[loct!=0] = 1 # so, each run of length l is l - 1 zeros--if we replace the nonzeros by ones, then we can count each run as a string of 0s
    str_reps =  ''.join([str(x) for x in loct]).split("1")  # convert to string, remove any characters that aren't '0's or '1's
    rls = [len(x) + 1 for x in str_reps] # get lengths l from (l-1) s
    assert sum(rls) == len(timeseries)
    return rls


def runlength_stats(rls:list)->dict:

    # find run lengths of some metric (number schools, achieved ratios, etc), and their counts, averages and  standard deviations
    # this is important because the distribution of run lengths between 
    assert len(rls) > 0
    rl_count = Counter(rls)
    rl_mean = np.mean(rls)
    rl_std = np.std(rls)
    rl_med = np.median(rls)
    return {'counts':rl_count, 'mean':rl_mean, 'median':rl_med, 'stddev':rl_std}







@dataclass
class SchoolDistrict:
    # core simulation class: represents the history of a single school district
    # BASIC SIMULATION PARAMETERS (CONSTANTS)
    sscRat: int = 100 # student to school ratio
    tolerance: tuple = (-0.5, 0.25) # tolerances for that ratio
    alphas:tuple = tuple(np.linspace(0.1,0.9,9)) # starting set of exponential smoothing parameters
    growth_period:int = 10 # number of years to follow a particular growth pattern
    n_periods:int = 6 # number of growth periods to run the simulation
    start_yr:int = 10 # year to begin forecasts
    noisy:bool = False # add noise to trajectory?
    school_lifetime:int = 30 # expected life of a school
    school_open_cost:float = -9. # cost to open a school
    school_close_cost:float = 1. # cost to close a school
    school_fund_fraction:float = 0.01 # how many other schools should revenue above the cost of maintenance go to fund?
    starting_fund_yrs:int = 2 # how many years of surplus to start with?
    school_minimum_threshold:float = -50. # what value of budget means no construction and no closure?
    interest_rate:float = 0.05 # how much is savings worth
    loan_multiplier:float = 0.7 # how much smaller is the interest to be paid vs. interest on assets?
    # BASIC SIMULATION PARAMETERS (VARIABLE)
    NStudents:int = 1000 # initial number of students
    pred_ratios: list = field(default_factory=list) # agent-predicted student/resource ratios
    ach_ratios: list = field(default_factory=list) # achieved student/resource ratios
    hist_alphas: list = field(default_factory=list)
    predictions: list = field(default_factory=list)
    hist_schools: list = field(default_factory=list)
    hist_budget: list = field(default_factory=list)



    def simulate_full_history(self,to_debug=False,set_history=None):
        # first step in the simulation--initialize the population history
        self.len_history = self.n_periods * self.growth_period
        self.history=simulate_history(start_value=self.NStudents,
                                      total_years=self.len_history,
                                      period_length=self.growth_period,
                                      noisy=self.noisy,
                                      debug=to_debug,
                                      set_history=set_history)

    def make_construction_decisions(self,debug=True):
        # at the end of every year, make a forecast and update alpha selection probabilities
        self.NSchools = self.NStudents // (self.sscRat + self.tolerance[1])# initial number of schools--started to be near a phase transition
        self.pselect = np.ones(len(self.alphas))/len(self.alphas) # selection probabilities for exponential smoothing parameters
        self.funding_rate = (1. + self.school_fund_fraction)/(self.sscRat * self.school_lifetime)
        last_alpha = 0.0 # initalize the most recent choice of exponential smoothing param
        alpha_multiple, extra = 1, 1 #divmod(self.len_history - self.start_yr, 5*len(self.alphas)) # number of times to include an alpha in the list,
        #--must guarantee that we won't run out of alphas
        local_as = list(self.alphas)*alpha_multiple  + [choice(self.alphas) for x in range(extra)]
        self.ach_ratios += list(np.zeros(self.start_yr-1))
        self.predictions += list(np.zeros(self.start_yr))
        self.pred_ratios += list(np.zeros(self.start_yr))
        self.hist_alphas += list(np.zeros(self.start_yr))
        self.hist_schools += list(np.ones(self.start_yr)*self.NSchools)
        self.hist_budget += list(np.zeros(self.start_yr - 1)) + [self.starting_fund_yrs*self.funding_rate *self.NStudents*-1*self.school_open_cost]

        for yr in range(self.start_yr, self.len_history):
            if self.NSchools == 0:
                print("Simulation terminated early. Zero schools left.")
                break

            # calculate ratio (evaluate performance) and update list of smoothing params
            local_achrat = self.history[yr-1]/self.NSchools # achieved ratio
            self.ach_ratios.append(local_achrat)
            self.hist_schools.append(self.NSchools)
            local_diff = (local_achrat - self.sscRat)/self.sscRat # achieved difference from ideal
            if yr > self.start_yr and last_alpha in local_as:
                if local_diff > self.tolerance[1] and len(local_as) > 1: #achieved ratio too high
                    local_as.remove(last_alpha)
                elif local_diff < self.tolerance[0] and len(local_as) > 1: #achieved ratio too low
                    local_as.remove(last_alpha)
                else: # ratio ok--good prediction
                    local_as.append(last_alpha)


            # forecast
            forecast_objs = predict_from_history(self.history[0:yr],years=1,alpha_set=local_as)
            local_prat = forecast_objs['prediction'][0]/self.NSchools
            self.hist_alphas.append(forecast_objs['alpha_result'])
            last_alpha = forecast_objs['alpha_result']
            local_ach_diff = (local_prat - self.sscRat)/self.sscRat# predicted difference from ideal
            self.predictions.append(forecast_objs['prediction'][0])
            self.pred_ratios.append(local_prat)

            # update number of schools based on forecast

            sch_change = np.round(self.NSchools*(local_ach_diff))

            open_close_cost = self.school_open_cost*sch_change if sch_change > 0 else self.school_close_cost*sch_change
            # print(f"existing budget is ${self.hist_budget[-1]}, need  ${open_close_cost} for opening/closing. ")

            if (self.hist_budget[-1] + open_close_cost) >= self.school_minimum_threshold:
                self.NSchools = np.round(self.NSchools*(1 + local_ach_diff))
            else: # can't afford to act
                open_close_cost = 0.

            interest =  self.hist_budget[-1]*self.interest_rate
            if self.hist_budget[-1]:
                interest *= self.loan_multiplier

            budget_change = self.history[yr]*self.funding_rate + open_close_cost + interest
            # print(f"budget changing by ${budget_change}, including ${open_close_cost} for opening/closing. ")
            self.hist_budget.append(self.hist_budget[-1] + budget_change)
            # update budget to reflect openings and closings
            if debug:
                print(len(local_as))
                print(local_as)
                print(Counter(local_as))
                print(f"schools should change by {self.NSchools*(local_ach_diff)}, or {sch_change}")
                print(f"existing budget is ${self.hist_budget[-1]}, need  ${open_close_cost} for opening/closing. ")
                print(f"budget changing by ${budget_change}, including ${open_close_cost} for opening/closing. ")

    def plot_history_vs_preds(self):
        # plotting actual vs predicted enrollment
        fig, ax = plt.subplots()
        ax.step(x=range(len(self.history)), y=self.history)
        ax.step(x=range(len(self.predictions)), y=self.predictions)
        ax.legend(['historical','predictions'])
        ax.set_title("Time Series of Historical vs. Predicted Enrollment")
        ax.set_ylabel("# Students")
        plt.show()
        plt.close()


    def plot_ratios(self):
        # plotting achieved vs actual student/school ratio
        fig, ax = plt.subplots()
        ax.step(x=range(len(self.ach_ratios)), y=self.ach_ratios)
        ax.step(x=range(len(self.pred_ratios)), y=self.pred_ratios)
        ax.hlines((self.tolerance[0] + 1)*self.sscRat, xmin=0, xmax=self.len_history,color="gray")
        ax.hlines((self.tolerance[1] + 1)*self.sscRat, xmin=0, xmax=self.len_history,color="gray")
        ax.fill_between(range(self.len_history), 0, (self.tolerance[0] + 1)*self.sscRat, color="gray", alpha=0.30)
        ax.fill_between(range(self.len_history),(self.tolerance[1] + 1)*self.sscRat, max(max(self.ach_ratios), max(self.pred_ratios)), color="gray", alpha=0.30)
        ax.legend(['achieved','predictions'])
        ax.set_title("Time Series of Predicted vs. Achieved Student/School Ratio")
        ax.set_ylabel("Students per School")
        ax.set_xlabel("Time (Years)")
        plt.show()
        plt.close()

    def plot_schools_vs_pop(self):
        # plotting number of schools vs. population (scaled)
        fig, ax = plt.subplots()
        ax.step(x=range(len(self.history)), y=minmax_scale(self.history))
        ax.step(x=range(len(self.hist_schools)), y=minmax_scale(self.hist_schools))
        ax.legend(['scaled population', 'scaled # schools'])
        ax.set_title(f"Time Series of Scaled # Schools, Total Enrollment\n#Schools: Min:{min(self.hist_schools)},Max:{max(self.hist_schools)}, Enrolled: Min:{min(self.history)},Max:{max(self.history)}")
        ax.set_ylabel("Scaled School Count/Scaled Enrollment")
        ax.set_xlabel("Time (Years)")
        plt.show()
        plt.close()

    # metrics
    def pct_when_performant(self, to_print=False):
        # give the proportion of school years where achieved student to resource ratios were within tolerance
        ach_test = self.ach_ratios[self.start_yr:]
        result_bool = [ (x <= ((self.tolerance[1] + 1)*self.sscRat) ) and (x >= ((self.tolerance[0] + 1)*self.sscRat)) for x in ach_test]
        prop = sum(result_bool)/len(result_bool)
        self.prop_perf = prop
        if to_print:
            print(f"The district was within tolerance bounds {np.round(100*prop)}% of the time.")
        return prop

    def plot_budget(self):
        # plotting budget
        fig, ax = plt.subplots()
        ax.step(x=range(len(self.hist_budget)), y=self.hist_budget)
        ax.legend(['Historical Budget'])
        ax.set_title(f"Time Series of Historical Budget")
        ax.hlines(self.school_minimum_threshold, xmin=0, xmax=self.len_history,color="red", linestyle="dotted")
        ax.hlines(0, xmin=0, xmax=self.len_history,color="gray", linestyle="dotted")
        ax.set_ylabel("Historical Budget ($)")
        ax.set_xlabel("Time (Years)")
        plt.show()
        plt.close()

    # metrics
    def pct_when_in_budget(self, lower_thresh=0, to_print=False):
        # give the proportion of school years where the budget was above some threshold ($0, -100% of total value of all schools, etc)
        # metric "ever reach ruin" can be calculated from this
        if len(self.hist_budget) < len(self.history):
            self.hist_budget += [0 for x in range(len(self.history) - len(self.hist_budget))]
        budget_res = self.hist_budget[self.start_yr:]
        result_bool = [ (x >= lower_thresh) for x in budget_res]
        prop = sum(result_bool)/len(result_bool)
        self.prop_perf = prop
        if to_print:
            print(f"The district budget was above the threshold of ${lower_thresh} {np.round(100*prop)}% of the time.")
        return prop


    def predictive_accuracy(self):
        # get Rsquared of predictions
        if len(self.history[self.start_yr:]) != len(self.predictions[self.start_yr:]):
            print("WARNING: HISTORY TERMINATED EARLY")
            lr = linregress(x=self.predictions[self.start_yr:], y=self.history[self.start_yr:len(self.predictions)])
        else:
            lr = linregress(x=self.predictions[self.start_yr:], y=self.history[self.start_yr:])

        return lr.rvalue








simSchool = SchoolDistrict(NStudents=2000, #Start with 2000 students
                           sscRat=250,  # ideal student/school ratio is 250
                           tolerance=(-.1,.1), #tolerate student/school ratios of 225 to 275
                           growth_period=20, # growth patterns last 20 years
                           n_periods=3, # run for 60 years in total
                           noisy=True, # add noise to population change
                           school_minimum_threshold = 0., # minimum budget to open/close a school
                           school_fund_fraction=0.95, # determines how much over current school operating expenses to charge in taxes
                           interest_rate=0.03,
                           pred_ratios=[], ach_ratios=[], hist_alphas=[], predictions=[],hist_budget=[]
                       )
simSchool.simulate_full_history()
simSchool.make_construction_decisions(debug=False)





simSchool.plot_history_vs_preds()


simSchool.predictive_accuracy()





simSchool.plot_ratios()


simSchool.pct_when_performant(to_print=True)





simSchool.plot_schools_vs_pop()





simSchool.plot_budget()


simSchool.pct_when_in_budget(lower_thresh=simSchool.school_minimum_threshold,to_print=True)





runlength_stats(get_run_lengths([int(x) for x in simSchool.hist_schools]))





Counter(simSchool.hist_alphas)


plt.plot(simSchool.hist_alphas)





def individual_replicate(SampleSize=2000,ratio=250, growth_patterns:list=[0,0,0], is_noisy:bool=False, alphas:tuple=None)->dict:
    # wrapper function to run a simulation in one school district under set conditions, 
    # and calculate predictive accuracy and metrics on performance ( % of time school to student ratio within tolerance, 
    # % of time budget within tolerance, median run length) 
    simSchool = SchoolDistrict(NStudents=SampleSize, #Start with 1250 students
                               sscRat=ratio,  # ideal student/school ratio is 250
                               tolerance=(-.1,.1), #tolerate student/school ratios of 225 to 275
                               growth_period=25, # growth patterns last 25 years
                               n_periods=len(growth_patterns), # run for 60 years
                               noisy=is_noisy, # add noise to population change
                               school_minimum_threshold = 0., # minimum budget to open/close a school
                               school_fund_fraction=0.70, # determines how much over current school operating expenses to charge in taxes
                               interest_rate=0.02,
                               pred_ratios=[], ach_ratios=[], hist_alphas=[], predictions=[],hist_budget=[]
                           )
    if alphas is not None:
        simSchool.alphas = alphas
    school_results = {}
    simSchool.simulate_full_history(set_history=growth_patterns)
    simSchool.make_construction_decisions(debug=False)
    
    school_results['r2'] = simSchool.predictive_accuracy()
    school_results['pct_performant'] = simSchool.pct_when_performant(to_print=False)
    school_results['pct_budgetary'] = simSchool.pct_when_in_budget(lower_thresh=simSchool.school_minimum_threshold,to_print=False)
    school_results['decision_length'] = runlength_stats(get_run_lengths([int(x) for x in simSchool.hist_schools]))['median']
    return school_results


expname = "baseline_2000_25_3_0budget_dl_out" # a name for a particular set of experimental conditions


def run_experiment(growth_pat_len:int=3, noise:bool=False, set_alpha=None, plot:bool=True):
    # perform a factorial experiment of all possible growth patterns of a certain length, 
    # with uniform noise added (or not) to the population trends 
    # and with a set alpha or optimized alpha 
    # returns the metrics for each combination of growth patterns 

    # analyze the experiment
    alphas_ = tuple(set_alpha for x in range(23)) if set_alpha is not None else None
    exp_result = {}
    pprod = product("0123456", repeat=growth_pat_len) # generate lists of all possible growth patterns
    formula = "decision_length ~ " + " + ".join([f"C(p{x})" for x in range(growth_pat_len)]) # formula for linear model of 
    # pct performant on 
    # print(formula)
    for pat in pprod:
        local_name = ",".join(pat)
        growth_pats =  [int(y) for y in pat]
        # print(growth_pats)
        local_res = individual_replicate(growth_patterns =growth_pats, is_noisy=noise, alphas=alphas_)
        exp_result[local_name] = local_res

    factorial = pd.DataFrame(exp_result).T
    for _,j in enumerate(range(growth_pat_len)):
        factorial[f'p{_}'] = factorial.index.to_series().apply(lambda x: x.split(',')[_])

    if plot:
        factorial.boxplot(column='r2', by='p0')
        factorial.boxplot(column='pct_budgetary', by='p0')
        factorial.boxplot(column='pct_performant', by='p0')
        factorial.boxplot(column='decision_length', by='p0')
        factorial.plot.scatter('decision_length', 'pct_performant', c=[int(x) for x in factorial['p1']], colormap='Dark2',alpha=0.3 )


    print(factorial[['r2', 'pct_budgetary', 'pct_performant','decision_length']].describe())

    lm = ols(formula, factorial).fit()
    print(lm.summary())
    print(anova_lm(lm))
    return factorial, lm


@dataclass
class SingleExperiment:
    # Single run from one set of experimental conditions (a wrapper to ci
    growth_pat_len:int=4
    noise:bool=False
    set_alpha:float=None
    plot:bool=False

    def run(self):
        self.name = f"gpl:{self.growth_pat_len};noise:{self.noise};A:{self.set_alpha}"
        self.result = run_experiment(growth_pat_len=self.growth_pat_len,
                       noise=self.noise, set_alpha=self.set_alpha, plot=self.plot)
        self.core_res = self.result[0][['r2', 'pct_budgetary', 'pct_performant','decision_length']].median()

    def get_result(self):
        self.run()
        return self.core_res






initial_class_test = SingleExperiment(growth_pat_len=3)
initial_class_test.get_result()


noisy_test = SingleExperiment(growth_pat_len=3,noise=True)
noisy_test.get_result()


a01_test = SingleExperiment(set_alpha=0.1, growth_pat_len=3)
a01_test.get_result()


na01_test = SingleExperiment(growth_pat_len=3, set_alpha=0.1, noise=True)
na01_test.get_result()


a09_test = SingleExperiment(growth_pat_len=3, set_alpha=0.9)
a09_test.get_result()


na09_test = SingleExperiment(growth_pat_len=3, set_alpha=0.9, noise=True,plot=True)
na09_test.get_result()


result_df = pd.DataFrame({x.name:x.core_res for x in [initial_class_test, noisy_test, a01_test, a09_test, na01_test, na09_test]}).T.sort_index()
result_df.to_csv(f"experiment_{expname}.csv")


initial_class_test.name


result_df


















